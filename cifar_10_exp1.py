# -*- coding: utf-8 -*-
"""Cifar_10_exp1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VukEJmGNig0e-DeHMfd3u488HpXRXrC4
"""

import keras
from keras.datasets import cifar10
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D
import os
from matplotlib import pyplot
from keras.optimizers import Adam, SGD
import cv2
from keras.utils import np_utils
import matplotlib.pyplot as plt
from sklearn import metrics
# from scipy.misc import toimage

# Define parameters and constants
numClasses = 10
batchSize = 128
epochs = 150
learning_rate = 0.01
decay = learning_rate/epochs



# Load the Cifar10 dataset
(x_train , y_train), (x_test, y_test) = cifar10.load_data()
print("shape of train data", x_train.shape)
print("shape of train label", y_train.shape)
print("shape of test data", x_test.shape)
print("shape of test label",y_test.shape)

# Display Cifar10 dataset
def display_imgs(X):
    plt.figure(1)
    k = 0
    for i in range(0,6):
        for j in range(0,6):
            plt.subplot2grid((6,6),(i,j))
            plt.imshow(X[k])
            k = k+1
    # show the plot
    plt.show()
    
    
display_imgs(x_test[:36])

# Normalize the input data
x_train = x_train/255.0
x_test = x_test/255.0

# convert labels to one hot encoding
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)

# Define the model architecture

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
model.add(Dropout(0.25))
model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(1000, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

# Compile the model
sgd = SGD(lr=learning_rate, momentum=0.9, decay=decay, nesterov=False)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])
print(model.summary())

# model.compile(loss='categorical_crossentropy',
#               optimizer=Adam(lr=learning_rate, decay=1e-6),
#               metrics=['accuracy'])

# Train the model
  model_history = model.fit(x_train, y_train,
              batch_size=batchSize,
              epochs=epochs,
              validation_data=(x_test, y_test),
              shuffle=True)

# Plot train and val accuray
plt.plot(model_history.history['acc'])
plt.plot(model_history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Plot train and val loss
plt.plot(model_history.history['loss'])
plt.plot(model_history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Evaluate overall model accuracy
scores = model.evaluate(x_test, y_test, verbose=0)
print("Accuracy: %.2f%%" % (scores[1]*100))
y_pred =model.predict(x_test)

# Calculate confusion matrix on the test set
matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))
print("confusion matrix", matrix)

