# -*- coding: utf-8 -*-
"""Cifar_10_exp3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L2gSqKxJntYRbOj5nbE1FSD762mzv6hY
"""

import keras
from keras.datasets import cifar10
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D,BatchNormalization
import os
from matplotlib import pyplot
from keras.optimizers import Adam, SGD
import cv2
from keras.utils import np_utils
import numpy as np

# Define Parameters and Constants
numClasses = 10
batchSize = 128
epochs = 200
learning_rate = 0.01
data_aug = True



# Load the Cifar10 dataset
(x_train , y_train), (x_test, y_test) = cifar10.load_data()
print("shape of train data", x_train.shape)
print("shape of train label", y_train.shape)
print("shape of test data", x_test.shape)
print("shape of test label",y_test.shape)

# Display Cifar10 dataset
def display_imgs(X):
    plt.figure(1)
    k = 0
    for i in range(0,6):
        for j in range(0,6):
            plt.subplot2grid((6,6),(i,j))
            plt.imshow(X[k])
            k = k+1
    # show the plot
    plt.show()
    
    
display_imgs(x_test[:36])

# Normalize the input data
x_train = x_train/255.0
x_test = x_test/255.0

# Convert to one hot encoding
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)

# Define the model Architecture

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(BatchNormalization())
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))
model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))
model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(1000, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

# Compile the model
decay = learning_rate/epochs
sgd = SGD(lr=learning_rate, momentum=0.9, decay=decay, nesterov=False)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])
print(model.summary())

# model.compile(loss='categorical_crossentropy',
#               optimizer=Adam(lr=learning_rate, decay=1e-6),
#               metrics=['accuracy'])


# Use Data Augmentation: For now only two types of data augmentations are tried
if data_aug:
  datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=False,rotation_range=15)
  datagen.fit(x_train)

  model_history = model.fit_generator(datagen.flow(x_train, y_train,
                                   batch_size=batchSize),
                      epochs=epochs,
                      validation_data=(x_test, y_test))
else:
   model_history =  model.fit(x_train, y_train,
            batch_size=batchSize,
            epochs=epochs,
            validation_data=(x_test, y_test),
            shuffle=True)

# Trained for some more epochs
  epochs = 80
  model_history = model.fit_generator(datagen.flow(x_train, y_train,
                                   batch_size=batchSize),
                      epochs=epochs,
                      validation_data=(x_test, y_test))



import matplotlib.pyplot as plt
from sklearn import metrics

# Plot model accuracy
plt.plot(model_history.history['acc'])
plt.plot(model_history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Plot model loss
plt.plot(model_history.history['loss'])
plt.plot(model_history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Evaluate oveall accuracy
scores = model.evaluate(x_test, y_test, verbose=0)
print("Accuracy: %.2f%%" % (scores[1]*100))
y_pred =model.predict(x_test)

# Calculate confusion matrix
matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))
print("matrix", matrix)

